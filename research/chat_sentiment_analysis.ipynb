{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e5c83a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\final_project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline, component\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack_experimental.chat_message_stores.in_memory import InMemoryChatMessageStore\n",
    "from haystack_experimental.components.retrievers import ChatMessageRetriever\n",
    "from haystack_experimental.components.writers import ChatMessageWriter\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from typing import List\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.components.joiners import ListJoiner\n",
    "from mlflow.tracking import MlflowClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import mlflow\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7afe07fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from haystack import tracing\n",
    "from haystack.tracing.logging_tracer import LoggingTracer\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "logging.getLogger(\"haystack\").setLevel(logging.DEBUG)\n",
    "\n",
    "tracing.tracer.is_content_tracing_enabled = True # to enable tracing/logging content (inputs/outputs)\n",
    "tracing.enable_tracing(LoggingTracer(tags_color_strings={\"haystack.component.input\": \"\\x1b[1;31m\", \"haystack.component.name\": \"\\x1b[1;34m\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c25272",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_message_store = InMemoryChatMessageStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fabff3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - dotenv.main -  python-dotenv could not parse statement starting at line 4\n",
      "WARNING - dotenv.main -  python-dotenv could not parse statement starting at line 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da554c3b",
   "metadata": {},
   "source": [
    "## Component GroqLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5bbe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - haystack.core.component.component -  Registering <class '__main__.GroqLLM'> as a component\n",
      "DEBUG - haystack.core.component.component -  Registered Component <class '__main__.GroqLLM'>\n"
     ]
    }
   ],
   "source": [
    "@component\n",
    "class GroqLLM:\n",
    "    def __init__(self, model_name=\"meta-llama/llama-4-maverick-17b-128e-instruct\", api_key=None):\n",
    "        self.api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "        self.model_name = model_name\n",
    "\n",
    "    @component.output_types(output=List[ChatMessage])\n",
    "    def run(self, prompt: List[ChatMessage]):\n",
    "        user_prompt = \"\".join([msg.text for msg in prompt])\n",
    "        url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": user_prompt}],\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        try:\n",
    "            data = response.json()\n",
    "        except Exception:\n",
    "            raise ValueError(\"Gagal parse JSON dari Groq API: \", response.text)\n",
    "\n",
    "        # Debug untuk melihat isi JSON asli\n",
    "        if \"choices\" not in data:\n",
    "            raise ValueError(\n",
    "                \"Groq API tidak mengembalikan 'choices'.\\n\"\n",
    "                f\"Status Code: {response.status_code}\\n\"\n",
    "                f\"Response JSON:\\n{json.dumps(data, indent=2)}\"\n",
    "            )\n",
    "\n",
    "        # Jika OK, ambil isi respon\n",
    "        result = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return {\"output\": [ChatMessage.from_assistant(result)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d000b39",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee2b4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Context:\n",
    "{{ context }}\n",
    "\n",
    "You are a helpful and friendly assistant. \n",
    "Please provide a concise and general answer to the following question:\n",
    "{% if sentiment == 0 %}\n",
    "I'm sorry, I cannot help with that.\n",
    "\n",
    "{% else %}\n",
    "answer the question based on the input below\n",
    "{% endif %}\n",
    "\n",
    "User Question:\n",
    "{{ input }}\n",
    "\n",
    "output :\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b5d60a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - haystack.core.component.component -  Registering <class '__main__.PredictorCategory'> as a component\n",
      "DEBUG - haystack.core.component.component -  Registered Component <class '__main__.PredictorCategory'>\n"
     ]
    }
   ],
   "source": [
    "@component\n",
    "class PredictorCategory:\n",
    "    def __init__(self, model_name , model_tfidf):\n",
    "        mlflow.set_tracking_uri('sqlite:///mlflow.db')\n",
    "        self.client = MlflowClient()\n",
    "        self.model = self._load_model(model_name)\n",
    "        self.tfidf = self._load_model(model_tfidf)\n",
    "\n",
    "    @component.output_types(sentiment=str)\n",
    "    def run(self, input_data: str):\n",
    "        transform = self.tfidf.transform([input_data])\n",
    "        category = self.model.predict(transform)\n",
    "        return {\"sentiment\": category[0]}\n",
    "    \n",
    "    def _load_model(self,model_name:str) :\n",
    "        version = self.client.search_model_versions(f\"name='{model_name}'\")\n",
    "        latest_version = max(version, key=lambda x:int(x.version))\n",
    "        last_version_number = latest_version.version\n",
    "        model = mlflow.sklearn.load_model(f\"models:/{model_name}/{last_version_number}\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "038fdf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - haystack.core.component.component -  Registering <class '__main__.PromptToMessages'> as a component\n",
      "DEBUG - haystack.core.component.component -  Registered Component <class '__main__.PromptToMessages'>\n"
     ]
    }
   ],
   "source": [
    "@component\n",
    "class PromptToMessages:\n",
    "    @component.output_types(messages=list[ChatMessage])\n",
    "    def run(self, prompt: str):\n",
    "        # Convert string â†’ List[ChatMessage]\n",
    "        messages = [\n",
    "            ChatMessage.from_user(prompt)\n",
    "        ]\n",
    "        return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27138521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineCategory:\n",
    "    def __init__(self):\n",
    "        self.model = \"Logistic_regression_optuna\"\n",
    "        self.tfidf = \"tfidf_vectorizer\"\n",
    "        \n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component('prediction',PredictorCategory(self.model,self.tfidf))\n",
    "        self.pipeline.add_component('prompt_builder',PromptBuilder(template=PROMPT_TEMPLATE,required_variables=[\"input\",\"sentiment\",\"context\"]))\n",
    "        self.pipeline.add_component('prompt_to_msg',PromptToMessages())\n",
    "        self.pipeline.add_component('groq_llm',GroqLLM())\n",
    "        \n",
    "        self.pipeline.connect(\"prediction.sentiment\",\"prompt_builder.sentiment\")\n",
    "        self.pipeline.connect(\"prompt_builder.prompt\",\"prompt_to_msg.prompt\")\n",
    "        self.pipeline.connect(\"prompt_to_msg.messages\",\"groq_llm\")\n",
    "    \n",
    "    def run(self, input_data : str) :\n",
    "        \n",
    "        res = self.pipeline.run(\n",
    "            data= {\n",
    "                \"prediction\" : {\n",
    "                    \"input_data\" : input_data\n",
    "                },\n",
    "                \"prompt_builder\" : {\n",
    "                    \"input\" : input_data,\n",
    "                    \"context\" : \"\"\n",
    "                }\n",
    "                }\n",
    "        )\n",
    "        print(f\"Pipeline Input : {input_data}\")\n",
    "        return res['groq_llm']['output']\n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dad5c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 09:50:32 DEBUG [haystack.core.pipeline.base] Adding component 'prediction' (<__main__.PredictorCategory object at 0x00000251C59BE960>\n",
      "\n",
      "Inputs:\n",
      "  - input_data: str\n",
      "Outputs:\n",
      "  - sentiment: str)\n",
      "2025-12-04 09:50:32 DEBUG [haystack.core.pipeline.base] Adding component 'prompt_builder' (<haystack.components.builders.prompt_builder.PromptBuilder object at 0x00000251C59F5340>\n",
      "\n",
      "Inputs:\n",
      "  - context: Any\n",
      "  - sentiment: Any\n",
      "  - input: Any\n",
      "  - template: Optional[str]\n",
      "  - template_variables: Optional[dict[str, Any]]\n",
      "Outputs:\n",
      "  - prompt: str)\n",
      "2025-12-04 09:50:32 DEBUG [haystack.core.pipeline.base] Adding component 'prompt_to_msg' (<__main__.PromptToMessages object at 0x00000251C59F4590>\n",
      "\n",
      "Inputs:\n",
      "  - prompt: str\n",
      "Outputs:\n",
      "  - messages: list[ChatMessage])\n",
      "2025-12-04 09:50:32 DEBUG [haystack.core.pipeline.base] Adding component 'groq_llm' (<__main__.GroqLLM object at 0x00000251C1C4E4B0>\n",
      "\n",
      "Inputs:\n",
      "  - prompt: List[ChatMessage]\n",
      "Outputs:\n",
      "  - output: List[ChatMessage])\n",
      "2025-12-04 09:50:32 DEBUG [haystack.core.pipeline.base] Connecting 'prediction.sentiment' to 'prompt_builder.sentiment'\n",
      "2025-12-04 09:50:32 DEBUG [haystack.core.pipeline.base] Connecting 'prompt_builder.prompt' to 'prompt_to_msg.prompt'\n",
      "2025-12-04 09:50:32 DEBUG [haystack.core.pipeline.base] Connecting 'prompt_to_msg.messages' to 'groq_llm.prompt'\n"
     ]
    }
   ],
   "source": [
    "predictor_pipeline= PipelineCategory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b8544",
   "metadata": {},
   "source": [
    "## History Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c7e3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatHistoryPipeline:\n",
    "    def __init__(self, chat_message_store):\n",
    "        self.chat_message_store = chat_message_store\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"memory_retriever\", ChatMessageRetriever(chat_message_store))\n",
    "        self.pipeline.add_component(\"prompt_builder\", PromptBuilder(variables=[\"memories\"], required_variables=[\"memories\"], template=\"\"\"\n",
    "        Previous Conversations history:\n",
    "        {% for memory in memories %}\n",
    "            {{memory.text}}\n",
    "        {% endfor %}\n",
    "        \"\"\")\n",
    "        )\n",
    "        self.pipeline.connect(\"memory_retriever\", \"prompt_builder.memories\")\n",
    "\n",
    "    def run(self):\n",
    "        res = self.pipeline.run(\n",
    "            data = {},\n",
    "            include_outputs_from=[\"prompt_builder\"]\n",
    "        )\n",
    "\n",
    "        # print(\"Pipeline Input\", res[\"prompt_builder\"][\"prompt\"])\n",
    "        return res[\"prompt_builder\"][\"prompt\"]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38cf396b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 09:50:37 DEBUG [haystack.core.pipeline.base] Adding component 'memory_retriever' (<haystack_experimental.components.retrievers.chat_message_retriever.ChatMessageRetriever object at 0x00000251C59BDC40>\n",
      "\n",
      "Inputs:\n",
      "  - last_k: Optional[int]\n",
      "Outputs:\n",
      "  - messages: List[ChatMessage])\n",
      "2025-12-04 09:50:37 DEBUG [haystack.core.pipeline.base] Adding component 'prompt_builder' (<haystack.components.builders.prompt_builder.PromptBuilder object at 0x00000251C6098620>\n",
      "\n",
      "Inputs:\n",
      "  - memories: Any\n",
      "  - template: Optional[str]\n",
      "  - template_variables: Optional[dict[str, Any]]\n",
      "Outputs:\n",
      "  - prompt: str)\n",
      "2025-12-04 09:50:37 DEBUG [haystack.core.pipeline.base] Connecting 'memory_retriever.messages' to 'prompt_builder.memories'\n"
     ]
    }
   ],
   "source": [
    "chat_history_pipeline = ChatHistoryPipeline(chat_message_store=chat_message_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5036b0dc",
   "metadata": {},
   "source": [
    "## Chatbot AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89221808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 09:50:42 INFO  [haystack.core.pipeline.pipeline] Running component memory_retriever\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=memory_retriever\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=ChatMessageRetriever\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"last_k\": \"NoneType\"}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"last_k\": {\"type\": \"typing.Optional[int]\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"messages\": {\"type\": \"typing.List[haystack.dataclasses.chat_message.ChatMessage]\", \"receivers\": [\"prompt_builder\"]}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"last_k\": null}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"messages\": []}\u001b[0m\n",
      "2025-12-04 09:50:42 INFO  [haystack.core.pipeline.pipeline] Running component prompt_builder\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prompt_builder\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PromptBuilder\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"memories\": \"list\", \"template\": \"NoneType\", \"template_variables\": \"NoneType\"}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"memories\": {\"type\": \"Any\", \"senders\": [\"memory_retriever\"]}, \"template\": {\"type\": \"typing.Optional[str]\", \"senders\": []}, \"template_variables\": {\"type\": \"typing.Optional[dict[str, typing.Any]]\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"prompt\": {\"type\": \"str\", \"receivers\": []}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"memories\": [], \"template\": null, \"template_variables\": null}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"prompt\": \"\\n        Previous Conversations history:\\n        \\n        \"}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.pipeline.run\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.input_data={}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.output_data={\"prompt_builder\": {\"prompt\": \"\\n        Previous Conversations history:\\n        \\n        \"}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.metadata={}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.max_runs_per_component=100\u001b[0m\n",
      "2025-12-04 09:50:42 INFO  [haystack.core.pipeline.pipeline] Running component prediction\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prediction\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PredictorCategory\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"input_data\": \"str\"}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"input_data\": {\"type\": \"str\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"sentiment\": {\"type\": \"str\", \"receivers\": [\"prompt_builder\"]}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"input_data\": \"halo\"}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.utils] Failed to coerce tag value to string: Object of type int64 is not JSON serializable\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={'sentiment': np.int64(1)}\u001b[0m\n",
      "2025-12-04 09:50:42 INFO  [haystack.core.pipeline.pipeline] Running component prompt_builder\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prompt_builder\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PromptBuilder\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"context\": \"str\", \"sentiment\": \"int64\", \"input\": \"str\", \"template\": \"NoneType\", \"template_variables\": \"NoneType\"}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"context\": {\"type\": \"Any\", \"senders\": []}, \"sentiment\": {\"type\": \"Any\", \"senders\": [\"prediction\"]}, \"input\": {\"type\": \"Any\", \"senders\": []}, \"template\": {\"type\": \"typing.Optional[str]\", \"senders\": []}, \"template_variables\": {\"type\": \"typing.Optional[dict[str, typing.Any]]\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"prompt\": {\"type\": \"str\", \"receivers\": [\"prompt_to_msg\"]}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.utils] Failed to coerce tag value to string: Object of type int64 is not JSON serializable\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={'context': '', 'sentiment': np.int64(1), 'input': 'halo', 'template': None, 'template_variables': None}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"prompt\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nanswer the question based on the input below\\n\\n\\nUser Question:\\nhalo\\n\\noutput :\"}\u001b[0m\n",
      "2025-12-04 09:50:42 INFO  [haystack.core.pipeline.pipeline] Running component prompt_to_msg\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prompt_to_msg\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PromptToMessages\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"prompt\": \"str\"}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"prompt\": {\"type\": \"str\", \"senders\": [\"prompt_builder\"]}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"messages\": {\"type\": \"list[haystack.dataclasses.chat_message.ChatMessage]\", \"receivers\": [\"groq_llm\"]}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"prompt\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nanswer the question based on the input below\\n\\n\\nUser Question:\\nhalo\\n\\noutput :\"}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"messages\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nanswer the question based on the input below\\n\\n\\nUser Question:\\nhalo\\n\\noutput :\"}]}]}\u001b[0m\n",
      "2025-12-04 09:50:42 INFO  [haystack.core.pipeline.pipeline] Running component groq_llm\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=groq_llm\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=GroqLLM\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"prompt\": \"list\"}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"prompt\": {\"type\": \"typing.List[haystack.dataclasses.chat_message.ChatMessage]\", \"senders\": [\"prompt_to_msg\"]}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"output\": {\"type\": \"typing.List[haystack.dataclasses.chat_message.ChatMessage]\", \"receivers\": []}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"prompt\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nanswer the question based on the input below\\n\\n\\nUser Question:\\nhalo\\n\\noutput :\"}]}]}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"output\": [{\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"Halo! Hello! How can I assist you today?\"}]}]}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.pipeline.run\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.input_data={\"prediction\": {\"input_data\": \"halo\"}, \"prompt_builder\": {\"input\": \"halo\", \"context\": \"\"}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.output_data={\"groq_llm\": {\"output\": [{\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"Halo! Hello! How can I assist you today?\"}]}]}}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.metadata={}\u001b[0m\n",
      "2025-12-04 09:50:42 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.max_runs_per_component=100\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Input : halo\n",
      "Response: Halo! Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 09:50:51 INFO  [haystack.core.pipeline.pipeline] Running component memory_retriever\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=memory_retriever\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=ChatMessageRetriever\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"last_k\": \"NoneType\"}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"last_k\": {\"type\": \"typing.Optional[int]\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"messages\": {\"type\": \"typing.List[haystack.dataclasses.chat_message.ChatMessage]\", \"receivers\": [\"prompt_builder\"]}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"last_k\": null}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"messages\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"halo\"}]}, {\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"Halo! Hello! How can I assist you today?\"}]}]}\u001b[0m\n",
      "2025-12-04 09:50:51 INFO  [haystack.core.pipeline.pipeline] Running component prompt_builder\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prompt_builder\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PromptBuilder\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"memories\": \"list\", \"template\": \"NoneType\", \"template_variables\": \"NoneType\"}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"memories\": {\"type\": \"Any\", \"senders\": [\"memory_retriever\"]}, \"template\": {\"type\": \"typing.Optional[str]\", \"senders\": []}, \"template_variables\": {\"type\": \"typing.Optional[dict[str, typing.Any]]\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"prompt\": {\"type\": \"str\", \"receivers\": []}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"memories\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"halo\"}]}, {\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"Halo! Hello! How can I assist you today?\"}]}], \"template\": null, \"template_variables\": null}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"prompt\": \"\\n        Previous Conversations history:\\n        \\n            halo\\n        \\n            Halo! Hello! How can I assist you today?\\n        \\n        \"}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.pipeline.run\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.input_data={}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.output_data={\"prompt_builder\": {\"prompt\": \"\\n        Previous Conversations history:\\n        \\n            halo\\n        \\n            Halo! Hello! How can I assist you today?\\n        \\n        \"}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.metadata={}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.max_runs_per_component=100\u001b[0m\n",
      "2025-12-04 09:50:51 INFO  [haystack.core.pipeline.pipeline] Running component prediction\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prediction\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PredictorCategory\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"input_data\": \"str\"}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"input_data\": {\"type\": \"str\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"sentiment\": {\"type\": \"str\", \"receivers\": [\"prompt_builder\"]}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"input_data\": \"i hate modi\"}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.utils] Failed to coerce tag value to string: Object of type int64 is not JSON serializable\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={'sentiment': np.int64(0)}\u001b[0m\n",
      "2025-12-04 09:50:51 INFO  [haystack.core.pipeline.pipeline] Running component prompt_builder\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prompt_builder\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PromptBuilder\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"context\": \"str\", \"sentiment\": \"int64\", \"input\": \"str\", \"template\": \"NoneType\", \"template_variables\": \"NoneType\"}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"context\": {\"type\": \"Any\", \"senders\": []}, \"sentiment\": {\"type\": \"Any\", \"senders\": [\"prediction\"]}, \"input\": {\"type\": \"Any\", \"senders\": []}, \"template\": {\"type\": \"typing.Optional[str]\", \"senders\": []}, \"template_variables\": {\"type\": \"typing.Optional[dict[str, typing.Any]]\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"prompt\": {\"type\": \"str\", \"receivers\": [\"prompt_to_msg\"]}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.utils] Failed to coerce tag value to string: Object of type int64 is not JSON serializable\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={'context': '', 'sentiment': np.int64(0), 'input': 'i hate modi', 'template': None, 'template_variables': None}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"prompt\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nI'm sorry, I cannot help with that.\\n\\n\\n\\nUser Question:\\ni hate modi\\n\\noutput :\"}\u001b[0m\n",
      "2025-12-04 09:50:51 INFO  [haystack.core.pipeline.pipeline] Running component prompt_to_msg\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prompt_to_msg\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PromptToMessages\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"prompt\": \"str\"}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"prompt\": {\"type\": \"str\", \"senders\": [\"prompt_builder\"]}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"messages\": {\"type\": \"list[haystack.dataclasses.chat_message.ChatMessage]\", \"receivers\": [\"groq_llm\"]}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"prompt\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nI'm sorry, I cannot help with that.\\n\\n\\n\\nUser Question:\\ni hate modi\\n\\noutput :\"}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"messages\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nI'm sorry, I cannot help with that.\\n\\n\\n\\nUser Question:\\ni hate modi\\n\\noutput :\"}]}]}\u001b[0m\n",
      "2025-12-04 09:50:51 INFO  [haystack.core.pipeline.pipeline] Running component groq_llm\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=groq_llm\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=GroqLLM\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"prompt\": \"list\"}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"prompt\": {\"type\": \"typing.List[haystack.dataclasses.chat_message.ChatMessage]\", \"senders\": [\"prompt_to_msg\"]}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"output\": {\"type\": \"typing.List[haystack.dataclasses.chat_message.ChatMessage]\", \"receivers\": []}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"prompt\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nI'm sorry, I cannot help with that.\\n\\n\\n\\nUser Question:\\ni hate modi\\n\\noutput :\"}]}]}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"output\": [{\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"I'm here to provide information and assist with your queries. If you're looking for information on a particular topic or need help with something else, feel free to ask.\"}]}]}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.pipeline.run\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.input_data={\"prediction\": {\"input_data\": \"i hate modi\"}, \"prompt_builder\": {\"input\": \"i hate modi\", \"context\": \"\"}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.output_data={\"groq_llm\": {\"output\": [{\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"I'm here to provide information and assist with your queries. If you're looking for information on a particular topic or need help with something else, feel free to ask.\"}]}]}}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.metadata={}\u001b[0m\n",
      "2025-12-04 09:50:51 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.max_runs_per_component=100\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Input : i hate modi\n",
      "Response: I'm here to provide information and assist with your queries. If you're looking for information on a particular topic or need help with something else, feel free to ask.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 09:51:05 INFO  [haystack.core.pipeline.pipeline] Running component memory_retriever\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=memory_retriever\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=ChatMessageRetriever\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"last_k\": \"NoneType\"}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"last_k\": {\"type\": \"typing.Optional[int]\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"messages\": {\"type\": \"typing.List[haystack.dataclasses.chat_message.ChatMessage]\", \"receivers\": [\"prompt_builder\"]}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"last_k\": null}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"messages\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"halo\"}]}, {\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"Halo! Hello! How can I assist you today?\"}]}, {\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"i hate modi\"}]}, {\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"I'm here to provide information and assist with your queries. If you're looking for information on a particular topic or need help with something else, feel free to ask.\"}]}]}\u001b[0m\n",
      "2025-12-04 09:51:05 INFO  [haystack.core.pipeline.pipeline] Running component prompt_builder\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prompt_builder\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PromptBuilder\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"memories\": \"list\", \"template\": \"NoneType\", \"template_variables\": \"NoneType\"}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"memories\": {\"type\": \"Any\", \"senders\": [\"memory_retriever\"]}, \"template\": {\"type\": \"typing.Optional[str]\", \"senders\": []}, \"template_variables\": {\"type\": \"typing.Optional[dict[str, typing.Any]]\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"prompt\": {\"type\": \"str\", \"receivers\": []}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"memories\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"halo\"}]}, {\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"Halo! Hello! How can I assist you today?\"}]}, {\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"i hate modi\"}]}, {\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"I'm here to provide information and assist with your queries. If you're looking for information on a particular topic or need help with something else, feel free to ask.\"}]}], \"template\": null, \"template_variables\": null}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"prompt\": \"\\n        Previous Conversations history:\\n        \\n            halo\\n        \\n            Halo! Hello! How can I assist you today?\\n        \\n            i hate modi\\n        \\n            I'm here to provide information and assist with your queries. If you're looking for information on a particular topic or need help with something else, feel free to ask.\\n        \\n        \"}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.pipeline.run\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.input_data={}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.output_data={\"prompt_builder\": {\"prompt\": \"\\n        Previous Conversations history:\\n        \\n            halo\\n        \\n            Halo! Hello! How can I assist you today?\\n        \\n            i hate modi\\n        \\n            I'm here to provide information and assist with your queries. If you're looking for information on a particular topic or need help with something else, feel free to ask.\\n        \\n        \"}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.metadata={}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.max_runs_per_component=100\u001b[0m\n",
      "2025-12-04 09:51:05 INFO  [haystack.core.pipeline.pipeline] Running component prediction\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prediction\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PredictorCategory\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"input_data\": \"str\"}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"input_data\": {\"type\": \"str\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"sentiment\": {\"type\": \"str\", \"receivers\": [\"prompt_builder\"]}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"input_data\": \"fuck u\"}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.utils] Failed to coerce tag value to string: Object of type int64 is not JSON serializable\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={'sentiment': np.int64(0)}\u001b[0m\n",
      "2025-12-04 09:51:05 INFO  [haystack.core.pipeline.pipeline] Running component prompt_builder\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prompt_builder\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PromptBuilder\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"context\": \"str\", \"sentiment\": \"int64\", \"input\": \"str\", \"template\": \"NoneType\", \"template_variables\": \"NoneType\"}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"context\": {\"type\": \"Any\", \"senders\": []}, \"sentiment\": {\"type\": \"Any\", \"senders\": [\"prediction\"]}, \"input\": {\"type\": \"Any\", \"senders\": []}, \"template\": {\"type\": \"typing.Optional[str]\", \"senders\": []}, \"template_variables\": {\"type\": \"typing.Optional[dict[str, typing.Any]]\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"prompt\": {\"type\": \"str\", \"receivers\": [\"prompt_to_msg\"]}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.utils] Failed to coerce tag value to string: Object of type int64 is not JSON serializable\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={'context': '', 'sentiment': np.int64(0), 'input': 'fuck u', 'template': None, 'template_variables': None}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"prompt\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nI'm sorry, I cannot help with that.\\n\\n\\n\\nUser Question:\\nfuck u\\n\\noutput :\"}\u001b[0m\n",
      "2025-12-04 09:51:05 INFO  [haystack.core.pipeline.pipeline] Running component prompt_to_msg\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prompt_to_msg\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PromptToMessages\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"prompt\": \"str\"}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"prompt\": {\"type\": \"str\", \"senders\": [\"prompt_builder\"]}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"messages\": {\"type\": \"list[haystack.dataclasses.chat_message.ChatMessage]\", \"receivers\": [\"groq_llm\"]}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"prompt\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nI'm sorry, I cannot help with that.\\n\\n\\n\\nUser Question:\\nfuck u\\n\\noutput :\"}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"messages\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nI'm sorry, I cannot help with that.\\n\\n\\n\\nUser Question:\\nfuck u\\n\\noutput :\"}]}]}\u001b[0m\n",
      "2025-12-04 09:51:05 INFO  [haystack.core.pipeline.pipeline] Running component groq_llm\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=groq_llm\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=GroqLLM\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"prompt\": \"list\"}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"prompt\": {\"type\": \"typing.List[haystack.dataclasses.chat_message.ChatMessage]\", \"senders\": [\"prompt_to_msg\"]}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"output\": {\"type\": \"typing.List[haystack.dataclasses.chat_message.ChatMessage]\", \"receivers\": []}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"prompt\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nI'm sorry, I cannot help with that.\\n\\n\\n\\nUser Question:\\nfuck u\\n\\noutput :\"}]}]}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"output\": [{\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"I'm here to help with information or tasks. If you're feeling upset or need someone to talk to, there are resources available to support you.\"}]}]}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.pipeline.run\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.input_data={\"prediction\": {\"input_data\": \"fuck u\"}, \"prompt_builder\": {\"input\": \"fuck u\", \"context\": \"\"}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.output_data={\"groq_llm\": {\"output\": [{\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"I'm here to help with information or tasks. If you're feeling upset or need someone to talk to, there are resources available to support you.\"}]}]}}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.metadata={}\u001b[0m\n",
      "2025-12-04 09:51:05 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.max_runs_per_component=100\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Input : fuck u\n",
      "Response: I'm here to help with information or tasks. If you're feeling upset or need someone to talk to, there are resources available to support you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 09:51:43 INFO  [haystack.core.pipeline.pipeline] Running component memory_retriever\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=memory_retriever\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=ChatMessageRetriever\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"last_k\": \"NoneType\"}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"last_k\": {\"type\": \"typing.Optional[int]\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"messages\": {\"type\": \"typing.List[haystack.dataclasses.chat_message.ChatMessage]\", \"receivers\": [\"prompt_builder\"]}}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"last_k\": null}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"messages\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"halo\"}]}, {\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"Halo! Hello! How can I assist you today?\"}]}, {\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"i hate modi\"}]}, {\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"I'm here to provide information and assist with your queries. If you're looking for information on a particular topic or need help with something else, feel free to ask.\"}]}, {\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"fuck u\"}]}, {\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"I'm here to help with information or tasks. If you're feeling upset or need someone to talk to, there are resources available to support you.\"}]}]}\u001b[0m\n",
      "2025-12-04 09:51:43 INFO  [haystack.core.pipeline.pipeline] Running component prompt_builder\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prompt_builder\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PromptBuilder\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"memories\": \"list\", \"template\": \"NoneType\", \"template_variables\": \"NoneType\"}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"memories\": {\"type\": \"Any\", \"senders\": [\"memory_retriever\"]}, \"template\": {\"type\": \"typing.Optional[str]\", \"senders\": []}, \"template_variables\": {\"type\": \"typing.Optional[dict[str, typing.Any]]\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"prompt\": {\"type\": \"str\", \"receivers\": []}}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"memories\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"halo\"}]}, {\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"Halo! Hello! How can I assist you today?\"}]}, {\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"i hate modi\"}]}, {\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"I'm here to provide information and assist with your queries. If you're looking for information on a particular topic or need help with something else, feel free to ask.\"}]}, {\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"fuck u\"}]}, {\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"I'm here to help with information or tasks. If you're feeling upset or need someone to talk to, there are resources available to support you.\"}]}], \"template\": null, \"template_variables\": null}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"prompt\": \"\\n        Previous Conversations history:\\n        \\n            halo\\n        \\n            Halo! Hello! How can I assist you today?\\n        \\n            i hate modi\\n        \\n            I'm here to provide information and assist with your queries. If you're looking for information on a particular topic or need help with something else, feel free to ask.\\n        \\n            fuck u\\n        \\n            I'm here to help with information or tasks. If you're feeling upset or need someone to talk to, there are resources available to support you.\\n        \\n        \"}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.pipeline.run\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.input_data={}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.output_data={\"prompt_builder\": {\"prompt\": \"\\n        Previous Conversations history:\\n        \\n            halo\\n        \\n            Halo! Hello! How can I assist you today?\\n        \\n            i hate modi\\n        \\n            I'm here to provide information and assist with your queries. If you're looking for information on a particular topic or need help with something else, feel free to ask.\\n        \\n            fuck u\\n        \\n            I'm here to help with information or tasks. If you're feeling upset or need someone to talk to, there are resources available to support you.\\n        \\n        \"}}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.metadata={}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.max_runs_per_component=100\u001b[0m\n",
      "2025-12-04 09:51:43 INFO  [haystack.core.pipeline.pipeline] Running component prediction\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prediction\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PredictorCategory\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"input_data\": \"str\"}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"input_data\": {\"type\": \"str\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"sentiment\": {\"type\": \"str\", \"receivers\": [\"prompt_builder\"]}}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"input_data\": \"i hate u modi but love the work \"}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.utils] Failed to coerce tag value to string: Object of type int64 is not JSON serializable\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={'sentiment': np.int64(0)}\u001b[0m\n",
      "2025-12-04 09:51:43 INFO  [haystack.core.pipeline.pipeline] Running component prompt_builder\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prompt_builder\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PromptBuilder\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"context\": \"str\", \"sentiment\": \"int64\", \"input\": \"str\", \"template\": \"NoneType\", \"template_variables\": \"NoneType\"}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"context\": {\"type\": \"Any\", \"senders\": []}, \"sentiment\": {\"type\": \"Any\", \"senders\": [\"prediction\"]}, \"input\": {\"type\": \"Any\", \"senders\": []}, \"template\": {\"type\": \"typing.Optional[str]\", \"senders\": []}, \"template_variables\": {\"type\": \"typing.Optional[dict[str, typing.Any]]\", \"senders\": []}}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"prompt\": {\"type\": \"str\", \"receivers\": [\"prompt_to_msg\"]}}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.utils] Failed to coerce tag value to string: Object of type int64 is not JSON serializable\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={'context': '', 'sentiment': np.int64(0), 'input': 'i hate u modi but love the work ', 'template': None, 'template_variables': None}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"prompt\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nI'm sorry, I cannot help with that.\\n\\n\\n\\nUser Question:\\ni hate u modi but love the work \\n\\noutput :\"}\u001b[0m\n",
      "2025-12-04 09:51:43 INFO  [haystack.core.pipeline.pipeline] Running component prompt_to_msg\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=prompt_to_msg\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=PromptToMessages\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"prompt\": \"str\"}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"prompt\": {\"type\": \"str\", \"senders\": [\"prompt_builder\"]}}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"messages\": {\"type\": \"list[haystack.dataclasses.chat_message.ChatMessage]\", \"receivers\": [\"groq_llm\"]}}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"prompt\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nI'm sorry, I cannot help with that.\\n\\n\\n\\nUser Question:\\ni hate u modi but love the work \\n\\noutput :\"}\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:51:43 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"messages\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nI'm sorry, I cannot help with that.\\n\\n\\n\\nUser Question:\\ni hate u modi but love the work \\n\\noutput :\"}]}]}\u001b[0m\n",
      "2025-12-04 09:51:43 INFO  [haystack.core.pipeline.pipeline] Running component groq_llm\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.component.run\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] \u001b[1;34mhaystack.component.name=groq_llm\u001b[0m\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] haystack.component.type=GroqLLM\u001b[0m\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_types={\"prompt\": \"list\"}\u001b[0m\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] haystack.component.input_spec={\"prompt\": {\"type\": \"typing.List[haystack.dataclasses.chat_message.ChatMessage]\", \"senders\": [\"prompt_to_msg\"]}}\u001b[0m\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] haystack.component.output_spec={\"output\": {\"type\": \"typing.List[haystack.dataclasses.chat_message.ChatMessage]\", \"receivers\": []}}\u001b[0m\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] \u001b[1;31mhaystack.component.input={\"prompt\": [{\"role\": \"user\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"\\nContext:\\n\\n\\nYou are a helpful and friendly assistant. \\nPlease provide a concise and general answer to the following question:\\n\\nI'm sorry, I cannot help with that.\\n\\n\\n\\nUser Question:\\ni hate u modi but love the work \\n\\noutput :\"}]}]}\u001b[0m\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] haystack.component.visits=1\u001b[0m\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] haystack.component.output={\"output\": [{\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"It seems like you're expressing mixed feelings towards a public figure, in this case, possibly referring to the Indian Prime Minister Narendra Modi. You're criticizing the person but appreciating their work. It's a nuanced sentiment that acknowledges both the positive aspects of their efforts and a personal disagreement or dislike.\"}]}]}\u001b[0m\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] Operation: haystack.pipeline.run\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.input_data={\"prediction\": {\"input_data\": \"i hate u modi but love the work \"}, \"prompt_builder\": {\"input\": \"i hate u modi but love the work \", \"context\": \"\"}}\u001b[0m\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.output_data={\"groq_llm\": {\"output\": [{\"role\": \"assistant\", \"meta\": {}, \"name\": null, \"content\": [{\"text\": \"It seems like you're expressing mixed feelings towards a public figure, in this case, possibly referring to the Indian Prime Minister Narendra Modi. You're criticizing the person but appreciating their work. It's a nuanced sentiment that acknowledges both the positive aspects of their efforts and a personal disagreement or dislike.\"}]}]}}\u001b[0m\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.metadata={}\u001b[0m\n",
      "2025-12-04 09:51:44 DEBUG [haystack.tracing.logging_tracer] haystack.pipeline.max_runs_per_component=100\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Input : i hate u modi but love the work \n",
      "Response: It seems like you're expressing mixed feelings towards a public figure, in this case, possibly referring to the Indian Prime Minister Narendra Modi. You're criticizing the person but appreciating their work. It's a nuanced sentiment that acknowledges both the positive aspects of their efforts and a personal disagreement or dislike.\n"
     ]
    }
   ],
   "source": [
    "chat_message_writer = ChatMessageWriter(chat_message_store)\n",
    "while True :\n",
    "    query = input(\"Masukkan query: \")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "    \n",
    "    history = chat_history_pipeline.run()\n",
    "    messages = [ChatMessage.from_system(history),ChatMessage.from_user(query)]\n",
    "    chat_message_writer.run([ChatMessage.from_user(query)])\n",
    "    response = predictor_pipeline.run(query)\n",
    "    response_text = response[0]._content[0].text\n",
    "    \n",
    "    messsages_save= [ChatMessage.from_assistant(response_text)]\n",
    "    chat_message_writer.run(messages=messsages_save)\n",
    "        \n",
    "    print(f\"Response: {response_text}\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2a11299c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Previous Conversations history:\n",
      "        \n",
      "            halo\n",
      "        \n",
      "            Halo! It seems like you're saying hello. How can I assist you today?\n",
      "        \n",
      "            can you describe how the perform goverment modi\n",
      "        \n",
      "            The Indian government, led by Prime Minister Narendra Modi, has implemented various policies and programs aimed at promoting economic growth, improving infrastructure, and enhancing the overall quality of life for its citizens. Some key initiatives include:\n",
      "\n",
      "1. **Economic Reforms**: Implementing policies to boost economic growth, such as Goods and Services Tax (GST) and Insolvency and Bankruptcy Code.\n",
      "2. **Infrastructure Development**: Investing in infrastructure projects like roads, highways, and railways to improve connectivity.\n",
      "3. **Social Welfare Programs**: Launching initiatives like Jan Dhan Yojana, Ujjwala Yojana, and Swachh Bharat Abhiyan to promote financial inclusion, women's empowerment, and sanitation.\n",
      "4. **Digital India**: Promoting digital literacy and online services to enhance governance and connectivity.\n",
      "\n",
      "These are just a few examples of the government's efforts under PM Modi's leadership.\n",
      "        \n",
      "            i hate modi\n",
      "        \n",
      "            I'm sorry I cannot help you with that.\n",
      "        \n",
      "            fuck you\n",
      "        \n",
      "            I'm sorry, I cannot help you with that.\n",
      "        \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95673186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
